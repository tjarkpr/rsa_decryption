{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from modules.transformer_layers import Transformer, CustomSchedule, masked_loss, masked_accuracy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "max_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/rsa_key_dataset.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['public'].to_numpy(), df['private'].to_numpy())\n",
    "train_examples = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "val_examples = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_input = tf.keras.layers.TextVectorization(split='character', max_tokens=max_features, output_mode='int')\n",
    "tokenizer_output = tf.keras.layers.TextVectorization(split='character', max_tokens=max_features, output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 16:40:36.103435: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "tokenizer_input.adapt(df['public'].to_numpy())\n",
    "tokenizer_output.adapt(df['private'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(input, output):\n",
    "    output = tokenizer_output(output)\n",
    "    output = output[:, :d_model]\n",
    "\n",
    "    input = tokenizer_input(input)\n",
    "    input = input[:, :(d_model+1)]\n",
    "    input_inputs = input[:, :-1]\n",
    "    input_labels = input[:, 1:]\n",
    "\n",
    "    return (output, input_inputs), input_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=max_features,\n",
    "    target_vocab_size=max_features,\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 10s 2s/step - loss: 8.5293 - masked_accuracy: 0.0000e+00 - val_loss: 8.5277 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.5266 - masked_accuracy: 0.0000e+00 - val_loss: 8.5233 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.5209 - masked_accuracy: 0.0000e+00 - val_loss: 8.5156 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.5150 - masked_accuracy: 0.0000e+00 - val_loss: 8.5045 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.5045 - masked_accuracy: 0.0000e+00 - val_loss: 8.4899 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.4908 - masked_accuracy: 0.0000e+00 - val_loss: 8.4718 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.4745 - masked_accuracy: 6.1035e-05 - val_loss: 8.4504 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.4536 - masked_accuracy: 6.1035e-05 - val_loss: 8.4255 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.4329 - masked_accuracy: 0.0000e+00 - val_loss: 8.3974 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.4073 - masked_accuracy: 6.1035e-05 - val_loss: 8.3661 - val_masked_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.3762 - masked_accuracy: 0.0014 - val_loss: 8.3316 - val_masked_accuracy: 6.2500e-04\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.3461 - masked_accuracy: 0.0034 - val_loss: 8.2942 - val_masked_accuracy: 0.0109\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.3130 - masked_accuracy: 0.0106 - val_loss: 8.2543 - val_masked_accuracy: 0.0409\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.2741 - masked_accuracy: 0.0316 - val_loss: 8.2119 - val_masked_accuracy: 0.0834\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.2362 - masked_accuracy: 0.0590 - val_loss: 8.1676 - val_masked_accuracy: 0.1350\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.1945 - masked_accuracy: 0.1100 - val_loss: 8.1218 - val_masked_accuracy: 0.1853\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.1520 - masked_accuracy: 0.1619 - val_loss: 8.0750 - val_masked_accuracy: 0.2359\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.1080 - masked_accuracy: 0.2177 - val_loss: 8.0277 - val_masked_accuracy: 0.2691\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.0622 - masked_accuracy: 0.2576 - val_loss: 7.9802 - val_masked_accuracy: 0.2959\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 5s 1s/step - loss: 8.0153 - masked_accuracy: 0.2878 - val_loss: 7.9335 - val_masked_accuracy: 0.2978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28128b010>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=20,\n",
    "                validation_data=val_batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
